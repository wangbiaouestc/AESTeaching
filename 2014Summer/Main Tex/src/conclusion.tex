This paper reviewed three different approaches to utilize parallel power of modern computers for the means of reaching a better video encoding performance 
using either the previous (H.264/AVC) or the current (H.265/HEVC) standard video codec. \\

In particularly the first paper \cite{Paper1} proposed a GPU based fast motion estimation framework for H.264/AVC with the main idea of tiling a frame. 
The ME of each tile is then to be calculated on a different GPU thread to reach a high level of parallelization. 
For this approach was only a case study, the results only indicated, that it is possible to reach a high level of parallelization, 
but with the implemented framework didn't prove to be efficient in speed or quality.\\

The second work \cite{Paper2} proposed a dynamic model for parallel H.264/AVC video encoding on hybrid GPU+CPU. 
Their main idea was to evaluate at runtime which device is more suitable for different tasks of the encoding algorithm. 
The implemented framework used the dynamic model and distributed every task according to the runtime analysis. 
Given the experimental results and the speed-ups they reached this dynamic model showed a lot of potential for certain hardware set-ups.\\

The last paper \cite{Paper3} used in contrary to the other two articles the H.265/HEVC codec. 
It described a proposal for a parallel CPU+GPU framework, that aims to execute VBSME and Interpolation on the GPU 
while executing every other task of the encoding algorithm on the CPU. 
Two synchronisation units take care of the communication between the devices and the steps they execute. 
A fast decision mode algorithm was introduced to approach the problem of the decision mode being the bottleneck of the framework. 
The results indicated a certain quality loss, but showed a huge speed-up.\\

\todo{this is the main conclusion, but is vague and weak, what is your opinion? is GPU appropriate for video coding job, if not why?}
Despite the first reviewed paper the other two showed potential improvements for the encoders of the used video codecs. 
Due to their limitations towards specific hardware like in the second paper or the rather poor comparison of results in the third paper. \\

\todo{the following paragraph seems coming from the air, I suggest remove it}
All three papers used high performance graphic cards for their experiments but none took the possibility of a multi-chip GPU or an multi-GPU system like SLI vom NVIDIA or Crossfire from AMD into account. 
\cite{multigpu} for instance created a job system to do just that. Combining the possible parallelization of certain algorithm of the video encoding process with the possible distribution to multiple GPUs 
would properly decrease the encoding time even more. But of course new challenges regarding data dependency would arise. \\

Future work in that field are only targeting the current codec H.265. 
Since it has been released different papers have already been released on improving the parallel capability of it, 
although the codec already includes parallel structures like tiles and wavefront parallel processing.